#!/bin/bash

# Pre-commit hook to check for duplicate files
# Little Secret Project - File Duplication Checker

echo "üîç ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ã‡πâ‡∏≥‡∏Å‡πà‡∏≠‡∏ô commit..."

# Check for duplicate JS files (excluding node_modules)
echo "üìù ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå JS..."
DUPLICATE_JS=$(find frontend backend -name "*.js" | xargs basename -s .js | sort | uniq -d)
if [ ! -z "$DUPLICATE_JS" ]; then
    echo "‚ö†Ô∏è  ‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå JS ‡∏ã‡πâ‡∏≥:"
    for file in $DUPLICATE_JS; do
        echo "   - $file.js"
        find frontend backend -name "$file.js"
    done
    echo ""
fi

# Check for duplicate HTML files
echo "üìÑ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå HTML..."
DUPLICATE_HTML=$(find frontend -name "*.html" | xargs basename -s .html | sort | uniq -d)
if [ ! -z "$DUPLICATE_HTML" ]; then
    echo "‚ö†Ô∏è  ‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå HTML ‡∏ã‡πâ‡∏≥:"
    for file in $DUPLICATE_HTML; do
        echo "   - $file.html"
        find frontend -name "$file.html"
    done
    echo ""
fi

# Check for old/backup files
echo "üóëÔ∏è  ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏Å‡πà‡∏≤/‡∏™‡∏≥‡∏£‡∏≠‡∏á..."
OLD_FILES=$(find . -name "*-old.*" -o -name "*-backup.*" -o -name "*.bak" -o -name "*~" | grep -v node_modules)
if [ ! -z "$OLD_FILES" ]; then
    echo "‚ö†Ô∏è  ‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏Å‡πà‡∏≤/‡∏™‡∏≥‡∏£‡∏≠‡∏á:"
    echo "$OLD_FILES"
    echo ""
fi

# Check for unused auth files
echo "üîê ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå auth ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ..."
UNUSED_AUTH=$(find frontend/js -name "*auth*" | grep -E "(old|backup|secure|temp)")
if [ ! -z "$UNUSED_AUTH" ]; then
    echo "‚ö†Ô∏è  ‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå auth ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ:"
    echo "$UNUSED_AUTH"
    echo ""
fi

# Check for large files that might be duplicates
echo "üì¶ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà..."
LARGE_FILES=$(find frontend backend -type f -size +100k | grep -v node_modules)
if [ ! -z "$LARGE_FILES" ]; then
    echo "üìä ‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà:"
    ls -lh $LARGE_FILES
    echo ""
fi

# Check for files with same content (using checksum)
echo "üî¢ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô..."
TEMP_FILE=$(mktemp)
find frontend backend -name "*.js" -o -name "*.html" -o -name "*.css" | xargs md5 > $TEMP_FILE 2>/dev/null
DUPLICATE_CONTENT=$(awk '{print $4}' $TEMP_FILE | sort | uniq -d)
if [ ! -z "$DUPLICATE_CONTENT" ]; then
    echo "‚ö†Ô∏è  ‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô:"
    for hash in $DUPLICATE_CONTENT; do
        echo "   Hash: $hash"
        grep "$hash" $TEMP_FILE
    done
    echo ""
fi
rm $TEMP_FILE

# Summary
echo "‚úÖ ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô"

# Exit with status 0 (allow commit) but show warnings
if [ ! -z "$DUPLICATE_JS" ] || [ ! -z "$DUPLICATE_HTML" ] || [ ! -z "$OLD_FILES" ] || [ ! -z "$UNUSED_AUTH" ]; then
    echo "‚ö†Ô∏è  ‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö ‡πÅ‡∏ï‡πà commit ‡∏¢‡∏±‡∏á‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡πà‡∏≠‡πÑ‡∏î‡πâ"
    echo "üí° ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡πâ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏≠‡∏Å"
fi

exit 0
